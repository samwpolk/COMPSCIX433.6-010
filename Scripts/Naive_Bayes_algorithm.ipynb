{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:09:50.200947Z",
     "start_time": "2020-07-14T03:09:47.270912Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:10:01.096550Z",
     "start_time": "2020-07-14T03:10:01.069025Z"
    }
   },
   "outputs": [],
   "source": [
    "# loading the iris dataset \n",
    "iris = datasets.load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:11:03.673072Z",
     "start_time": "2020-07-14T03:11:03.667845Z"
    }
   },
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y =iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:11:47.393317Z",
     "start_time": "2020-07-14T03:11:47.385027Z"
    }
   },
   "outputs": [],
   "source": [
    "iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:12:23.141375Z",
     "start_time": "2020-07-14T03:12:23.134988Z"
    }
   },
   "outputs": [],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:13:30.778432Z",
     "start_time": "2020-07-14T03:13:30.769216Z"
    }
   },
   "outputs": [],
   "source": [
    "(pd.DataFrame(X)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:14:03.360697Z",
     "start_time": "2020-07-14T03:14:03.341821Z"
    }
   },
   "outputs": [],
   "source": [
    "# dividing X, y into train and test data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state = 42) \n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:14:08.606582Z",
     "start_time": "2020-07-14T03:14:08.599768Z"
    }
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:15:35.734244Z",
     "start_time": "2020-07-14T03:15:35.621200Z"
    }
   },
   "outputs": [],
   "source": [
    "# training a Naive Bayes classifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "gnb_model = GaussianNB().fit(X_train, y_train) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:21:02.916950Z",
     "start_time": "2020-07-14T03:21:02.909898Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_gnb = gnb_model.predict(X_test) \n",
    "y_pred_gnb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:17:07.440290Z",
     "start_time": "2020-07-14T03:17:07.423574Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nCOnfusion Matrix gnb:\\n\", confusion_matrix(y_test, y_pred_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:17:41.320571Z",
     "start_time": "2020-07-14T03:17:41.307290Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy gnb: {:.2f}%\".format(accuracy_score(y_test, y_pred_gnb) * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:18:01.924821Z",
     "start_time": "2020-07-14T03:18:01.910225Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nClassification Report gnb:\\n\",classification_report(y_test, y_pred_gnb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:19:04.570512Z",
     "start_time": "2020-07-14T03:19:04.564473Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"GNB Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0],(y_test != y_pred_gnb).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nice piece of this Bayesian formalism is that it naturally allows for probabilistic classification, which we can compute using the predict_proba method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:20:11.766340Z",
     "start_time": "2020-07-14T03:20:11.750773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.97327448e-090, 9.95635767e-001, 4.36423302e-003],\n",
       "       [1.00000000e+000, 4.96158126e-014, 6.54922363e-021],\n",
       "       [7.31890302e-290, 4.92947614e-012, 1.00000000e+000],\n",
       "       [2.81842533e-094, 9.77593559e-001, 2.24064412e-002],\n",
       "       [1.13877801e-105, 8.70022596e-001, 1.29977404e-001],\n",
       "       [1.00000000e+000, 1.73180181e-013, 3.66170159e-021],\n",
       "       [5.90437185e-053, 9.99955645e-001, 4.43550046e-005],\n",
       "       [5.98735064e-177, 1.18219872e-006, 9.99998818e-001],\n",
       "       [4.01752535e-096, 9.92158276e-001, 7.84172366e-003],\n",
       "       [3.15071776e-059, 9.99938983e-001, 6.10171853e-005],\n",
       "       [4.44911663e-152, 5.88867020e-004, 9.99411133e-001],\n",
       "       [1.00000000e+000, 2.04863718e-017, 4.73585098e-025],\n",
       "       [1.00000000e+000, 4.22431128e-017, 1.86022566e-024],\n",
       "       [1.00000000e+000, 5.31248651e-017, 1.85939976e-024],\n",
       "       [1.00000000e+000, 8.92960033e-017, 4.55408899e-024],\n",
       "       [1.04918592e-107, 6.02930476e-001, 3.97069524e-001],\n",
       "       [6.78610052e-204, 5.05656256e-007, 9.99999494e-001],\n",
       "       [3.07256674e-055, 9.99982769e-001, 1.72305837e-005],\n",
       "       [1.46366429e-084, 9.98040608e-001, 1.95939244e-003],\n",
       "       [1.68882019e-192, 2.94971181e-006, 9.99997050e-001],\n",
       "       [1.00000000e+000, 5.98122647e-016, 1.63332320e-023],\n",
       "       [8.42966853e-128, 9.89169319e-002, 9.01083068e-001],\n",
       "       [1.00000000e+000, 1.43755981e-013, 2.80756525e-021],\n",
       "       [4.85851497e-185, 1.83103291e-005, 9.99981690e-001],\n",
       "       [9.62966511e-234, 1.64396056e-009, 9.99999998e-001],\n",
       "       [8.19796396e-181, 1.37161759e-006, 9.99998628e-001],\n",
       "       [9.32787870e-178, 6.28437300e-004, 9.99371563e-001],\n",
       "       [7.90472310e-219, 1.36528257e-008, 9.99999986e-001],\n",
       "       [1.00000000e+000, 2.08539921e-015, 1.67773682e-023],\n",
       "       [1.00000000e+000, 1.31930917e-015, 3.02915134e-023]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb_pred_prob = gnb_model.predict_proba(X_test) \n",
    "gnb_pred_prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns give the posterior probabilities of the labels. If you are looking for estimates of uncertainty in your classification, Bayesian approaches like this can be a useful approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb_model = MultinomialNB().fit(X_train, y_train) \n",
    "y_pred_mnb = mnb_model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy mnb: {:.2f}%\".format(accuracy_score(y_test, y_pred_mnb) * 100))\n",
    "print(\"\\nCOnfusion Matrix gnb:\\n\", confusion_matrix(y_test, y_pred_mnb))\n",
    "print(\"\\nClassification Report gnb:\\n\",classification_report(y_test, y_pred_mnb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another Example using label encoder\n",
    "\n",
    "In this example, we can use dummy dataset with three columns: weathre, temperature, and play. The first two are input features and the other is label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:27:16.523568Z",
     "start_time": "2020-07-14T03:27:16.516653Z"
    }
   },
   "outputs": [],
   "source": [
    "# Assigning features and label variables\n",
    "weather=['Sunny','Sunny','Overcast','Rainy','Rainy','Rainy','Overcast','Sunny','Sunny',\n",
    "'Rainy','Sunny','Overcast','Overcast','Rainy']\n",
    "\n",
    "temp=['Hot','Hot','Hot','Mild','Cool','Cool','Cool','Mild','Cool','Mild','Mild','Mild','Hot','Mild']\n",
    "\n",
    "play=['No','No','Yes','Yes','Yes','No','Yes','No','Yes','Yes','Yes','Yes','Yes','No']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding features\n",
    "First, you need to convert these strings labels into numbers. for example 'Overcast', 'Rainy', \"Sunny' as 0,1,2. This is know as label encoding. Scikit-learn provides LabelEncoder library for encoding labels with a value between 0 and one less than the number of discrete classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:27:21.897654Z",
     "start_time": "2020-07-14T03:27:21.882408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather: [2 2 0 1 1 1 0 2 2 1 2 0 0 1]\n",
      "Temp: [1 1 1 2 0 0 0 2 0 2 2 2 1 2]\n",
      "Play: [0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#creating labelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Converting string labels into numbers.\n",
    "weather_encoded=le.fit_transform(weather)\n",
    "print(\"Weather:\", weather_encoded)\n",
    "\n",
    "temp_encoded=le.fit_transform(temp)\n",
    "print(\"Temp:\",temp_encoded)\n",
    "\n",
    "label=le.fit_transform(play)\n",
    "print(\"Play:\",label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now combine both the features (weather and temp) in a single variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:28:05.190776Z",
     "start_time": "2020-07-14T03:28:04.878696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    weather  temp\n",
       "0         2     1\n",
       "1         2     1\n",
       "2         0     1\n",
       "3         1     2\n",
       "4         1     0\n",
       "5         1     0\n",
       "6         0     0\n",
       "7         2     2\n",
       "8         2     0\n",
       "9         1     2\n",
       "10        2     2\n",
       "11        0     2\n",
       "12        0     1\n",
       "13        1     2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=pd.DataFrame(zip(weather_encoded,temp_encoded))\n",
    "X.columns = ['weather', 'temp']\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating Model\n",
    "\n",
    "Generate a model using Naive Bayes classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:28:41.164554Z",
     "start_time": "2020-07-14T03:28:41.153252Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Train the model using the training sets\n",
    "nb_model.fit(X,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-14T03:28:59.878866Z",
     "start_time": "2020-07-14T03:28:59.871842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: [0 1]\n"
     ]
    }
   ],
   "source": [
    "# Predcit output\n",
    "\n",
    "pred = nb_model.predict([[2,1], [0,1]])\n",
    "print(\"Predicted Value:\", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes\n",
    "The Gaussian assumption just described is by no means the only simple assumption that could be used to specify the generative distribution for each label. Another useful example is multinomial naive Bayes, where the features are assumed to be generated from a simple multinomial distribution. The multinomial distribution describes the probability of observing counts among a number of categories, and thus multinomial naive Bayes is most appropriate for features that represent counts or count rates.\n",
    "\n",
    "The idea is precisely the same as before, except that instead of modeling the data distribution with the best-fit Gaussian, we model the data distribuiton with a best-fit multinomial distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example: Classifying Text\n",
    "\n",
    "One place where multinomial naive Bayes is often used is in text classification, where the features are related to word counts or frequencies within the documents to be classified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "review_data = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = fetch_20newsgroups(subset = 'train')\n",
    "test = fetch_20newsgroups(subset = 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.data[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use this data for machine learning, we need to be able to convert the content of each string into a vector of numbers. For this we will use the TF-IDF vectorizer, and create a pipeline that attaches it to a multinomial naive Bayes classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train.data, train.target)\n",
    "labels = model.predict(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(test.target, labels)\n",
    "\n",
    "\n",
    "print(\"Accuracy mnb: {:.2f}%\".format(accuracy_score(test.target, labels) * 100))\n",
    "print(\"\\nCOnfusion Matrix gnb:\\n\", confusion_matrix(test.target, labels))\n",
    "print(\"\\nClassification Report gnb:\\n\",classification_report(test.target, labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=train.target_names, yticklabels=train.target_names)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
